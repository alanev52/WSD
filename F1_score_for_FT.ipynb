{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13pwJrbHvTyzUeEtm2W6nDpw-Rp5dDpm9","authorship_tag":"ABX9TyMULeNGqbEl+qO2Xe1xK+v1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# F1 scores of embeddings from fine-tuning\n","\n"," The notebook processes test data through a fine-tuned BERT model and generates CSV files containing F1 scores, specifically F1_micro, F1_weighted, and F1_macro scores."],"metadata":{"id":"T3tbHRz7tfYQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKPgTm5t3iUe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import json\n","\n","def parse_test_data(data_path):\n","    directories = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n","    directories = sorted(directories)\n","    PRED = {}\n","    for folder in directories:\n","      words = [d for d in os.listdir(data_path+'/'+folder)]\n","      for word_file in words:\n","        if 'test.gold' in word_file:\n","          path = f\"{data_path}/{folder}/{word_file}\"\n","          with open(path, \"r\", encoding=\"utf-8\") as f:\n","            p = []\n","            lines = f.readlines()\n","            for line in lines:\n","              line = line.strip('\\ufeff')\n","              p.append(int(line.strip('\\n')))\n","              PRED[word_file+'_'+folder] = p\n","    return PRED, directories\n","gold_path = '/content/drive/MyDrive/RD_project/MERGED_DATA/WSD_full'\n","t, words = parse_test_data(gold_path)\n","for k, v in t.items():\n","  print(f'{k}:{v}')"],"metadata":{"id":"KjNhrpR3zxIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","\n","def parse_out_data(data_path):\n","    directories = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n","    PRED = {}\n","    for folder in directories[1:len(directories)]:\n","      words = [d for d in os.listdir(data_path+'/'+folder)]\n","      for word_file in words:\n","        if '_acc' not in word_file:\n","          path = f\"{data_path}/{folder}/{word_file}\"\n","          with open(path, \"r\") as f:\n","            p = []\n","            lines = f.readlines()\n","            for line in lines:\n","              p.append(int(line.strip('\\n')))\n","              PRED[folder+'_'+word_file] = p\n","    return PRED\n","data_path = '/content/drive/MyDrive/RD_project/output'\n","\n","d = parse_out_data(data_path)\n","for k, v in d.items():\n","  print(f'{k}:{v}')\n"],"metadata":{"id":"Y4hqOC903p6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","w_classes = {}\n","def parse_classes(path):\n","    directories = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n","    PRED = {}\n","    for w_folder in directories:\n","      files = [d for d in os.listdir(path+'/'+w_folder)]\n","      #print(\"files:\", files)\n","      for file in files:\n","          #print(file)\n","          if file == 'classes_map.txt':\n","              file_path = os.path.join(path, w_folder, file)\n","              with open(file_path, 'r', encoding='utf-8') as f:\n","                  for line in f:\n","                      classes = json.loads(line)\n","                      classes[\"ALL\"] = 'ALL'\n","                      w_classes[w_folder] = classes\n","    return (w_classes)\n","\n","classes_path = '/content/drive/MyDrive/RD_project/MERGED_DATA/WSD_full'\n","w_classes = parse_classes(classes_path)\n","print(w_classes)"],"metadata":{"id":"VSSDyVj_PL8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","ru_summary_path = '/content/drive/MyDrive/RD_project/results/WSD_full/ft/DeepPavlov/summary_f1.csv'\n","m_summary_path = '/content/drive/MyDrive/RD_project/results/WSD_full/ft/mBERT/summary_f1.csv'\n","\n","ru_directory = os.path.dirname(ru_summary_path)\n","m_directory = os.path.dirname(m_summary_path)\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(ru_directory):\n","    os.makedirs(ru_directory)\n","if not os.path.exists(m_directory):\n","    os.makedirs(m_directory)\n","\n","def gold_info(GOLD_test):\n","    gold_by_senses = {}\n","    all_preds = {}\n","    for n in range(len(set(GOLD_test))):\n","        list_all = []\n","        for i, sense in enumerate(GOLD_test):\n","            if sense == n:\n","                list_all.append(i)\n","            gold_by_senses[str(n)] = len(list_all)\n","            all_preds['all_%d' %(n)] =list_all\n","    #print(gold_by_senses)\n","    return gold_by_senses, all_preds\n","\n","\n","def correct_pred(GOLD_test, PRED, all_preds):\n","    correct_pred = {}\n","    for n in range(len(set(GOLD_test))):\n","        for i, pred in enumerate(PRED):\n","            if i in all_preds['all_%d' %(n)] and PRED[i] == GOLD_test[i]:\n","                correct_pred[str(n)] = correct_pred.get(str(n), 0) + 1\n","    return correct_pred\n","\n","\n","def accuracies(GOLD_BY_SENSES, correct):\n","    senses_accs = {}\n","    ALL = 0\n","    for s in gold_by_senses:\n","        if s in correct:\n","            sense_acc = correct[s] / gold_by_senses[s]\n","            senses_accs[s] = round(sense_acc,3)\n","        else:\n","            senses_accs[s] = 0\n","    ALL = sum(correct.values())/sum(GOLD_BY_SENSES.values())\n","    senses_accs['ALL'] = round(ALL,3)\n","    return senses_accs\n","\n","\n","r_summary = {\n","    'word': [],\n","    'sense': [],\n","    'number of instances': [],\n","    'f1_micro': [],\n","    'f1_weighted': [],\n","    'f1_macro': []\n","}\n","m_summary = {\n","    'word': [],\n","    'sense': [],\n","    'number of instances': [],\n","    'f1_micro': [],\n","    'f1_weighted': [],\n","    'f1_macro': []\n","}\n","for word in words:\n","\n","    if (f'test.gold.txt_%s' %word in t.keys() and\n","        f'multilingual_%s.txt' %word in d.keys() or\n","        f'rubert_%s.txt' %word in d.keys()):\n","        GOLD_test = t['test.gold.txt_%s' %word]\n","        PRED_M = d['multilingual_%s.txt' %word]\n","        PRED_RU = d['rubert_%s.txt' %word]\n","        gold_by_senses, all_preds = gold_info(GOLD_test)\n","        m = correct_pred(GOLD_test, PRED_M, all_preds)\n","        r = correct_pred(GOLD_test, PRED_RU, all_preds)\n","        ru_accuracy = accuracies(gold_by_senses, r)\n","        m_accuracy = accuracies(gold_by_senses, m)\n","        ru_f1_macro = np.round(f1_score(GOLD_test, PRED_RU, average=None),3)\n","        m_f1_macro = np.round(f1_score(GOLD_test, PRED_M, average=None),3)\n","        ru_f1_weighted = f1_score(GOLD_test, PRED_RU, average='weighted')\n","        m_f1_weighted = f1_score(GOLD_test, PRED_M, average='weighted')\n","\n","        r_summary['word'].extend([word] * len(ru_accuracy))\n","        r_summary['sense'].extend(list(w_classes[word].values()))\n","        r_summary['number of instances'].extend(list(gold_by_senses.values()) + [sum(gold_by_senses.values())])\n","        r_summary['f1_micro'].extend(list(ru_accuracy.values()))\n","        #print([round(ru_f1_weighted,3)])\n","        r_summary['f1_weighted'].extend(list(ru_accuracy.values())[:-1] + [round(ru_f1_weighted,3)])\n","        r_summary['f1_macro'].extend(list(ru_f1_macro) + [sum(ru_f1_macro/len(ru_f1_macro))])\n","\n","        m_summary['word'].extend([word] * len(m_accuracy))\n","        m_summary['sense'].extend(list(m_accuracy.keys()))\n","        m_summary['number of instances'].extend(list(gold_by_senses.values()) + [sum(gold_by_senses.values())])\n","        m_summary['f1_micro'].extend(list(m_accuracy.values()))\n","        m_summary['f1_weighted'].extend(list(m_accuracy.values())[:-1] + [round(m_f1_weighted,3)])\n","        m_summary['f1_macro'].extend(list(m_f1_macro) + [sum(m_f1_macro/len(m_f1_macro))])\n","\n","\n","r_df = pd.DataFrame(r_summary)\n","m_df = pd.DataFrame(m_summary)\n","\n","r_df.to_csv(ru_summary_path, index=False)\n","m_df.to_csv(m_summary_path, index=False)\n","\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1701104073590,"user_tz":-60,"elapsed":1989,"user":{"displayName":"Anastasia Alexandrova","userId":"03869832558556348480"}},"id":"7PHhDI4M8-Xo"},"execution_count":6,"outputs":[]}]}