{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDG10cAKTAjRne6xqgucKJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# F1 scores of embeddings from fine-tuning\n","\n"," The notebook processes through test data & fine-tuned BERT models and generates CSV files containing F1 scores, specifically F1_micro, F1_weighted, and F1_macro scores as well as TXT files with predictions of the 3 independent rounds for each word for the further analysis"],"metadata":{"id":"T3tbHRz7tfYQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKPgTm5t3iUe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Parsing gold_dataset, outputs from FT-models predictions and senses maps"],"metadata":{"id":"-brDq6bDxsGP"}},{"cell_type":"code","source":["import os\n","import json\n","\n","def parse_test_data(data_path):\n","    directories = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n","    directories = sorted(directories)\n","    PRED = {}\n","    for folder in directories:\n","      words = [d for d in os.listdir(data_path+'/'+folder)]\n","      for word_file in words:\n","        if 'test.gold' in word_file:\n","          path = f\"{data_path}/{folder}/{word_file}\"\n","          with open(path, \"r\", encoding=\"utf-8\") as f:\n","            p = []\n","            lines = f.readlines()\n","            for line in lines:\n","              line = line.strip('\\ufeff')\n","              p.append(int(line.strip('\\n')))\n","              PRED[word_file+'_'+folder] = p\n","    return PRED, directories\n","gold_path = '/content/drive/MyDrive/RD_project/MERGED_DATA/WSD_full'\n","t, words = parse_test_data(gold_path)\n","# for k, v in t.items():\n","#   print(f'{k}:{v}')"],"metadata":{"id":"KjNhrpR3zxIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","\n","def parse_out_data(data_path):\n","    directories = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n","    PRED = {}\n","    for folder in directories[0:len(directories)]:\n","      words = [d for d in os.listdir(data_path+'/'+folder)]\n","      for word_file in words:\n","        if '_acc' not in word_file:\n","          path = f\"{data_path}/{folder}/{word_file}\"\n","          with open(path, \"r\") as f:\n","            p = []\n","            lines = f.readlines()\n","            for line in lines:\n","              p.append(int(line.strip('\\n')))\n","              PRED[folder+'_'+word_file] = p\n","    return PRED\n","data_path = '/content/drive/MyDrive/RD_project/output'\n","data_path_2 = '/content/drive/MyDrive/RD_project/output2'\n","data_path_3 = '/content/drive/MyDrive/RD_project/output3'\n","\n","\n","d1 = parse_out_data(data_path)\n","d2 = parse_out_data(data_path_2)\n","d3 = parse_out_data(data_path_3)\n"],"metadata":{"id":"Y4hqOC903p6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","w_classes = {}\n","def parse_classes(path):\n","    directories = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n","    PRED = {}\n","    for w_folder in directories:\n","      files = [d for d in os.listdir(path+'/'+w_folder)]\n","      #print(\"files:\", files)\n","      for file in files:\n","          #print(file)\n","          if file == 'classes_map.txt':\n","              file_path = os.path.join(path, w_folder, file)\n","              with open(file_path, 'r', encoding='utf-8') as f:\n","                  for line in f:\n","                      classes = json.loads(line)\n","                      classes[\"ALL\"] = 'ALL'\n","                      w_classes[w_folder] = classes\n","    return (w_classes)\n","\n","classes_path = '/content/drive/MyDrive/RD_project/MERGED_DATA/WSD_full'\n","w_classes = parse_classes(classes_path)\n","print(w_classes)"],"metadata":{"id":"VSSDyVj_PL8I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Calculating F1-scores for all FT-models"],"metadata":{"id":"wkWvOQ3UyLvX"}},{"cell_type":"code","source":["from inspect import modulesbyfile\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","import os\n","\n","def gold_info(GOLD_test):\n","    gold_by_senses = {}\n","    all_preds = {}\n","    for n in range(len(set(GOLD_test))):\n","        list_all = [i for i, sense in enumerate(GOLD_test) if sense == n]\n","        gold_by_senses[str(n)] = len(list_all)\n","        all_preds['all_%d' %(n)] = list_all\n","    return gold_by_senses, all_preds\n","\n","def correct_pred(GOLD_test, PRED, all_preds):\n","    correct_pred = {}\n","    for n in range(len(set(GOLD_test))):\n","        correct_pred[str(n)] = sum(1 for i, pred in enumerate(PRED) if i in all_preds['all_%d' %(n)] and PRED[i] == GOLD_test[i])\n","    return correct_pred\n","\n","def accuracies(GOLD_BY_SENSES, correct):\n","    senses_accs = {}\n","    for s in GOLD_BY_SENSES:\n","        if s in correct:\n","            sense_acc = correct[s] / GOLD_BY_SENSES[s]\n","            senses_accs[s] = round(sense_acc, 3)\n","        else:\n","            senses_accs[s] = 0\n","    senses_accs['ALL'] = round(sum(correct.values()) / sum(GOLD_BY_SENSES.values()), 3)\n","    return senses_accs\n","\n","def process_data(data, gold_test, w_classes, result_path, summary_path):\n","    summary = {\n","        'word': [],\n","        'sense': [],\n","        'number of instances': [],\n","        'f1_micro': [],\n","        'f1_weighted': [],\n","        'f1_macro': []\n","    }\n","\n","    for word in words:\n","        f1_scores = {model: 0 for model in ['ru', 'm', 'b']}\n","        weighted_f1 = {model: 0 for model in ['ru', 'm', 'b']}\n","        accuracy = {model: [] for model in ['ru', 'm', 'b']}\n","        predictions = {model: [] for model in ['ru', 'm', 'b']}\n","\n","        for d in data:\n","            if f'test.gold.txt_{word}' in t.keys() and f'multilingual_{word}.txt' in d.keys():\n","                gold_test_word = t[f'test.gold.txt_{word}']\n","                pred_m = d[f'multilingual_{word}.txt']\n","                pred_b = d[f'other_model_{word}.txt']\n","                pred_ru = d[f'rubert_{word}.txt']\n","                gold_by_senses, all_preds = gold_info(gold_test_word)\n","                m = correct_pred(gold_test_word, pred_m, all_preds)\n","                r = correct_pred(gold_test_word, pred_ru, all_preds)\n","                b = correct_pred(gold_test_word, pred_b, all_preds)\n","\n","                accuracy['ru'].append(accuracies(gold_by_senses, r))\n","                accuracy['m'].append(accuracies(gold_by_senses, m))\n","                accuracy['b'].append(accuracies(gold_by_senses, b))\n","\n","                for model, pred in zip(['ru', 'm', 'b'], [pred_ru, pred_m, pred_b]):\n","                    f1_scores[model] += np.round(f1_score(gold_test_word, pred, average=None), 3)\n","                    weighted_f1[model] += f1_score(gold_test_word, pred, average='weighted')\n","                    predictions[model].append(pred)\n","\n","        for model in ['ru', 'm', 'b']:\n","\n","            avg_accuracy = {k1: round(((x + y + z) / 3),3) for (k1, x), (k2, y), (k3, z) in zip(accuracy[model][0].items(),\n","                                                                                                accuracy[model][1].items(),\n","                                                                                                accuracy[model][2].items())}\n","\n","\n","            #avg_accuracy = {k: round(sum(v) / len(v), 3) for k, v in accuracy[model][i].items() for i in range(3)}\n","            summary['word'].extend([word] * len(avg_accuracy))\n","            summary['sense'].extend(list(w_classes[word].values()))\n","            summary['number of instances'].extend(list(gold_by_senses.values()) + [sum(gold_by_senses.values())])\n","            summary['f1_micro'].extend(list(avg_accuracy.values()))\n","            summary['f1_weighted'].extend(list(avg_accuracy.values())[:-1] + [round(weighted_f1[model] / len(data), 3)])\n","            summary['f1_macro'].extend(list(np.round(f1_scores[model] / len(data), 3)) +\n","                                       [sum(np.round(f1_scores[model] / len(data), 3)) / len(np.round(f1_scores[model] / len(data), 3))])\n","\n","        with open(result_path, 'a', encoding='utf-8') as file:\n","            file.write('%s,%s,%s\\n'  % ('word', word, 'results:'))\n","            for prediction in predictions['ru']:\n","                file.write('%s\\n' % (prediction))\n","\n","    df = pd.DataFrame(summary)\n","    df.to_csv(summary_path, index=False)\n","\n","# Define file paths\n","file_paths = {\n","    'ru_summary_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/DeepPavlov/summary_f1_all.csv',\n","    'm_summary_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/mBERT/summary_f1_all.csv',\n","    'b_summary_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/bBERT/summary_f1_all.csv',\n","    'ru_result_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/DeepPavlov/all_results.txt',\n","    'm_result_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/mBERT/all_results.txt',\n","    'b_result_path': '/content/drive/MyDrive/RD_project/results/WSD_full/ft/bBERT/all_results.txt'\n","}\n","\n","# Create directories if they don't exist\n","for file_path in file_paths.values():\n","    directory = os.path.dirname(file_path)\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","process_data([d1, d2, d3], t, w_classes, file_paths['ru_result_path'], file_paths['ru_summary_path'])\n","process_data([d1, d2, d3], t, w_classes, file_paths['m_result_path'], file_paths['m_summary_path'])\n","process_data([d1, d2, d3], t, w_classes, file_paths['b_result_path'], file_paths['b_summary_path'])"],"metadata":{"id":"YWUeor5-cgAH"},"execution_count":null,"outputs":[]}]}