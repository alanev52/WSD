{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODn6HIji/ia/MUagZa9Hw7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Merged results table\n","The notebook takes as input summary files of all the systems with f1 scores and outputs merges CSV file with all the metrics scores."],"metadata":{"id":"jxf075wwY_8f"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyOgKVAvXB_8"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","# Replace these file paths with your actual file paths\n","fnn_ru = \"/content/drive/MyDrive/RD_project/results/WSD_full/1nn/DeepPavlov/rubert-base-cased/summary_f1.csv\"\n","fnn_m = \"/content/drive/MyDrive/RD_project/results/WSD_full/1nn/bert-base-multilingual-cased/summary_f1.csv\"\n","ft_ru = \"/content/drive/MyDrive/RD_project/results/WSD_full/ft/DeepPavlov/summary_f1.csv\"\n","ft_m = \"/content/drive/MyDrive/RD_project/results/WSD_full/ft/mBERT/summary_f1.csv\"\n","fnn_b = \"/content/drive/MyDrive/RD_project/results/WSD_full/1nn/bert-base-uncased/summary_f1.csv\"\n","ft_b = \"/content/drive/MyDrive/RD_project/results/WSD_full/ft/mBERT/summary_f1.csv\"\n","\n","# Read initial CSV file into a separate DataFrame\n","df_1nn_ru = pd.read_csv(fnn_ru, encoding='utf-8')\n","\n","\n","# Read the last column from the other three CSV files\n","columns_to_add = []\n","for file in [fnn_m, fnn_b, ft_ru, ft_m, ft_b]:\n","    temp_df = pd.read_csv(file)\n","    last_columns = temp_df.iloc[:, -3:]  # We want the last 3 column\n","    columns_to_add.append(last_columns)\n","\n","# Concatenate the columns to add to the first DataFrame\n","columns_concatenated = pd.concat(columns_to_add, axis=1)\n","columns_concatenated.columns = ['f1_micro_1nn_m', 'f1_weighted_1nn_m', 'f1_macro_1nn_m',\n","                                'f1_micro_1nn_b', 'f1_weighted_1nn_b', 'f1_macro_1nn_b',\n","                                'f1_micro_ft_ru', 'f1_weighted_ft_ru', 'f1_macro_ft_ru',\n","                                'f1_micro_ft_m', 'f1_weighted_ft_m', 'f1_macro_ft_m',\n","                                'f1_micro_ft_b', 'f1_weighted_ft_b', 'f1_macro_ft_b']\n","\n","df_1nn_ru.rename(columns={'f1_micro': 'f1_micro_1nn_ru',\n","                          'f1_weighted':'f1_weighted_1nn_ru',\n","                          'f1_macro': 'f1_macro_1nn_ru'}, inplace=True)\n","\n","# Concatenate the first DataFrame with the additional columns\n","merged_df = pd.concat([df_1nn_ru, columns_concatenated], axis=1)\n","\n","\n","merged_file_path = '/content/drive/MyDrive/RD_project/results/WSD_full/merged_file_av.csv'\n","merged_df.to_csv(merged_file_path, index=False, encoding='utf-8')\n"],"metadata":{"id":"JrFE7pAvHtG7","executionInfo":{"status":"ok","timestamp":1702378887578,"user_tz":-60,"elapsed":610,"user":{"displayName":"Anastasia Alexandrova","userId":"03869832558556348480"}}},"execution_count":5,"outputs":[]}]}